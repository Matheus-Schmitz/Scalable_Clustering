{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjacent-wages",
   "metadata": {},
   "source": [
    "# Scalable Clustering\n",
    "\n",
    "Implementation of a batch-based clustering algorithm inspired by the Bradley-Fayyad-Reina algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-camping",
   "metadata": {},
   "source": [
    "## 1. Imports & Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "heated-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "internal-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import cluster\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aggressive-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the time the algorithm takes\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "average-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input paths\n",
    "input_file = \"./publicdata/clustering_dataset.txt\"\n",
    "n_cluster = 10\n",
    "output_file = \"predictions.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-azerbaijan",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "copyrighted-damage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 322312\n"
     ]
    }
   ],
   "source": [
    "# Read the input file (without using spark!)\n",
    "with open(input_file, 'r') as f_in:\n",
    "    dataset = np.array(f_in.readlines())\n",
    "    \n",
    "print(f'Dataset size: {dataset.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "round-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datapoint_id': 308450,\n",
       " 'true_cluster': 6,\n",
       " 'features': [-15.620078012764438,\n",
       "  30.046543370390356,\n",
       "  51.30861319371247,\n",
       "  59.19104682368959,\n",
       "  -45.46259766274144,\n",
       "  -46.32738916055233,\n",
       "  -38.88754664939637,\n",
       "  -29.587487734159385,\n",
       "  -40.75516794238417,\n",
       "  -34.46822234404671]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conver the dataset to a dict for easily accessing the relevant information from a sample's id\n",
    "dataset_dict = {}\n",
    "for row in dataset:\n",
    "    row_data = row.replace(\"\\n\",\"\").split(\",\")\n",
    "    dataset_dict[int(row_data[0])] = {'datapoint_id': int(row_data[0]), \n",
    "                                      'true_cluster': int(row_data[1]), \n",
    "                                      'features': [float(feat) for feat in row_data[2:]]}\n",
    "    \n",
    "# View sample\n",
    "dataset_dict[np.random.choice(list(dataset_dict.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fundamental-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dimensionality: 10\n",
      "Mahalanobis Threshold: 6.324555320336759\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset's dimensionality \n",
    "dataset_dimensionality = len(dataset_dict[0]['features'])\n",
    "print(f'Dataset Dimensionality: {dataset_dimensionality}')\n",
    "\n",
    "# Calculate the Mahalanobis threshold to be used\n",
    "mahalanobis_threshold = 2 * np.sqrt(dataset_dimensionality)\n",
    "print(f'Mahalanobis Threshold: {mahalanobis_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beautiful-rings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 64463\n"
     ]
    }
   ],
   "source": [
    "# From the file figure out the sample size for each of the 5 iterations\n",
    "sample_size = math.ceil(len(dataset)*0.2)\n",
    "print(f'Sample Size: {sample_size}')\n",
    "\n",
    "# List all sample_ids which have not yet been clustered\n",
    "unused_ids = set(dataset_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-palmer",
   "metadata": {},
   "source": [
    "## 3. Initialize Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "pleased-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the objects for the different sets\n",
    "DS_CLUSTERS = dict()\n",
    "DISCARD_SET_stats = dict()\n",
    "COMPRESSION_SET_stats = dict()\n",
    "RETAINED_SET = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "large-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the first round of data to initialize the algorithm\n",
    "round_1_samples = random.sample(unused_ids, sample_size)\n",
    "for sample_id in round_1_samples:\n",
    "    unused_ids.remove(sample_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fifty-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the K-Means training data from the round_1_samples\n",
    "init_sample_features = []\n",
    "for sample_id in round_1_samples:\n",
    "    init_sample_features.append(dataset_dict[sample_id]['features'])\n",
    "X_train = np.array(init_sample_features)\n",
    "\n",
    "# Run K-Means (e.g., from sklearn) with a large K (e.g., 5 times of the number of the input clusters)\n",
    "kmeans = cluster.KMeans(n_clusters=10*n_cluster)\n",
    "predicted_clusters = kmeans.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "outstanding-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign points to clusters\n",
    "init_clusters = dict()\n",
    "for cluster_id, sampled_id in zip(predicted_clusters, round_1_samples):\n",
    "    # If there is no key for the current cluster id, create one \n",
    "    if init_clusters.get(cluster_id) == None:\n",
    "        init_clusters[cluster_id] = []\n",
    "    init_clusters[cluster_id].append(sampled_id)\n",
    "\n",
    "# Move lone points to the RETAINED_SET\n",
    "for cluster_id, clustered_points in init_clusters.items():\n",
    "    if len(clustered_points) == 1:\n",
    "        RETAINED_SET.append(clustered_points[0])\n",
    "        round_1_samples.remove(clustered_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "focal-outreach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87905,\n",
       " 177195,\n",
       " 97437,\n",
       " 293977,\n",
       " 231763,\n",
       " 181374,\n",
       " 62431,\n",
       " 273890,\n",
       " 111817,\n",
       " 14724,\n",
       " 48647,\n",
       " 263667,\n",
       " 251550,\n",
       " 156334,\n",
       " 275282,\n",
       " 93860]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which points ended up in the retained set\n",
    "RETAINED_SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "diagnostic-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the round_1_samples after having moved outliers to the RS\n",
    "train_sample_features = []\n",
    "for sample_id in round_1_samples:\n",
    "    train_sample_features.append(dataset_dict[sample_id]['features'])\n",
    "X_train = np.array(train_sample_features)\n",
    "kmeans = cluster.KMeans(n_clusters=n_cluster)\n",
    "predicted_clusters = kmeans.fit_predict(X_train)\n",
    "\n",
    "# Assign points to DS clusters\n",
    "for cluster_id, sampled_id in zip(predicted_clusters, round_1_samples):\n",
    "    # If there is no key for the current cluster id, create one \n",
    "    if DS_CLUSTERS.get(cluster_id) == None:\n",
    "        DS_CLUSTERS[cluster_id] = []\n",
    "    DS_CLUSTERS[cluster_id].append(sampled_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "partial-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cluster statistics for the clusters generated from the initialization round\n",
    "for key, value in DS_CLUSTERS.items():\n",
    "    DISCARD_SET_stats[key] = {'ids_in_cluster': []}\n",
    "    features_matrix = []\n",
    "    for datapoint in value:\n",
    "        DISCARD_SET_stats[key]['ids_in_cluster'].append(datapoint)\n",
    "        features_matrix.append(dataset_dict[datapoint]['features'])\n",
    "    features_matrix = np.array(features_matrix)\n",
    "    DISCARD_SET_stats[key]['N'] = len(DISCARD_SET_stats[key]['ids_in_cluster'])\n",
    "    DISCARD_SET_stats[key]['sum'] = features_matrix.sum(axis=0)\n",
    "    DISCARD_SET_stats[key]['sumsq'] = np.sum(features_matrix**2, axis=0)\n",
    "    DISCARD_SET_stats[key]['stdev'] = np.sqrt(\n",
    "                                              (DISCARD_SET_stats[key]['sumsq']/DISCARD_SET_stats[key]['N']) - \n",
    "                                              (np.square(DISCARD_SET_stats[key]['sum']) / DISCARD_SET_stats[key]['N']**2)\n",
    "                                         )\n",
    "    DISCARD_SET_stats[key]['centroid'] = DISCARD_SET_stats[key]['sum']/DISCARD_SET_stats[key]['N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fossil-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KMeans on the RETAINED_SET and generate COMPRESSION_SET clusters\n",
    "RS_sample_features = []\n",
    "for sample_id in RETAINED_SET:\n",
    "    RS_sample_features.append(dataset_dict[sample_id]['features'])\n",
    "X_train = np.array(RS_sample_features)\n",
    "# If there were any samples in the RS, cluster them\n",
    "RS_clusters = {}\n",
    "if X_train.shape[0] > 0:\n",
    "    kmeans = cluster.KMeans(n_clusters=min(7*n_cluster, int(1 + (X_train.shape[0]/2))))\n",
    "    predicted_clusters = kmeans.fit_predict(X_train)\n",
    "    for cluster_id, sampled_id in zip(predicted_clusters, RETAINED_SET):\n",
    "        # If there is no key for the current cluster id, create one\n",
    "        if RS_clusters.get(cluster_id) == None:\n",
    "            RS_clusters[cluster_id] = list()\n",
    "        # Then append the RS sample to the its newly found CS cluster\n",
    "        RS_clusters[cluster_id].append(sampled_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "specified-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cluster statistics for the clusters generated from the initialization round\n",
    "for key, value in RS_clusters.items():\n",
    "\n",
    "    # Only clusters with more than one sample in them go to the CS, those with only 1 sample remain RS \n",
    "    if len(value) > 1:\n",
    "\n",
    "        COMPRESSION_SET_stats[key] = {'ids_in_cluster': []}\n",
    "        features_matrix = []\n",
    "        for datapoint in value:\n",
    "            COMPRESSION_SET_stats[key]['ids_in_cluster'].append(datapoint)\n",
    "            features_matrix.append(dataset_dict[datapoint]['features'])\n",
    "        features_matrix = np.array(features_matrix)\n",
    "        COMPRESSION_SET_stats[key]['N'] = len(COMPRESSION_SET_stats[key]['ids_in_cluster'])\n",
    "        COMPRESSION_SET_stats[key]['sum'] = features_matrix.sum(axis=0)\n",
    "        COMPRESSION_SET_stats[key]['sumsq'] = np.sum(features_matrix**2, axis=0)\n",
    "        COMPRESSION_SET_stats[key]['stdev'] = np.sqrt(\n",
    "                                                  (COMPRESSION_SET_stats[key]['sumsq']/COMPRESSION_SET_stats[key]['N']) - \n",
    "                                                  (np.square(COMPRESSION_SET_stats[key]['sum']) / COMPRESSION_SET_stats[key]['N']**2)                                                     \n",
    "                                             )\n",
    "        COMPRESSION_SET_stats[key]['centroid'] = COMPRESSION_SET_stats[key]['sum']/COMPRESSION_SET_stats[key]['N']\n",
    "\n",
    "        # Clean the samples from the retained set which have been summarized\n",
    "        for datapoint in value:\n",
    "            RETAINED_SET.remove(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "alpine-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 | DS Points: 64447 | CS Clusters: 5 | CS Points: 12 | RS Points: 4\n"
     ]
    }
   ],
   "source": [
    "# Objects to tally values to be outputted\n",
    "num_DS_points = 0 \n",
    "num_CS_clusters = 0\n",
    "num_CS_points = 0\n",
    "num_RS_points = 0\n",
    "\n",
    "# Tally the values for outputting\n",
    "for key, value in DISCARD_SET_stats.items():\n",
    "    num_DS_points += value['N']\n",
    "for key, value in COMPRESSION_SET_stats.items():\n",
    "    num_CS_clusters += 1\n",
    "    num_CS_points += value['N']\n",
    "num_RS_points = len(RETAINED_SET)\n",
    "\n",
    "# Write the results for the initialization round (round 1)\n",
    "f_out = open(output_file, \"w\")\n",
    "f_out.write(\"The intermediate results:\")\n",
    "f_out.write(\"\\n\" + \"Round 1: \" + str(num_DS_points) + \",\" + str(num_CS_clusters) + \",\" + str(num_CS_points) + \",\" + str(num_RS_points))\n",
    "print(f\"Round 1 | DS Points: {str(num_DS_points)} | CS Clusters: {str(num_CS_clusters)} | CS Points: {str(num_CS_points)} | RS Points: {str(num_RS_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-extra",
   "metadata": {},
   "source": [
    "## 4. Run Batch Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "composed-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_cluster_mahalanobis_distance(datapoint_idx, cluster_stats):\n",
    "    \n",
    "    stdev = cluster_stats['stdev']\n",
    "    centroid = cluster_stats['centroid']\n",
    "    mahalanobis_distance = 0\n",
    "    for dim in range(dataset_dimensionality):\n",
    "        mahalanobis_distance += ((dataset_dict[datapoint_idx]['features'][dim] - centroid[dim]) / stdev[dim])**2\n",
    "    mahalanobis_distance = np.sqrt(mahalanobis_distance)\n",
    "\n",
    "    return mahalanobis_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "organic-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercluster_mahalanobis_distance(left_cluster_stats, right_cluster_stats): # takes the dict value\n",
    "    \n",
    "    stdev1, centroid1 = left_cluster_stats['stdev'], left_cluster_stats['centroid']\n",
    "    stdev2, centroid2 = right_cluster_stats['stdev'], right_cluster_stats['centroid']\n",
    "\n",
    "    # Calculate the mahalanobis distance between the clusters\n",
    "    left_cluster_dist, right_cluster_dist = 0, 0\n",
    "    for dim in range(dataset_dimensionality):\n",
    "        left_cluster_dist += ((centroid1[dim] - centroid2[dim]) / stdev2[dim])**2\n",
    "        right_cluster_dist += ((centroid2[dim] - centroid1[dim]) / stdev1[dim])**2\n",
    "    left_cluster_dist = np.sqrt(left_cluster_dist)\n",
    "    right_cluster_dist = np.sqrt(right_cluster_dist)\n",
    "\n",
    "    return min(left_cluster_dist, right_cluster_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "reduced-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_CS_CS(key1, key2):\n",
    "    COMPRESSION_SET_stats[key1]['ids_in_cluster'].extend(COMPRESSION_SET_stats[key2]['ids_in_cluster'])\n",
    "    COMPRESSION_SET_stats[key1]['N'] += COMPRESSION_SET_stats[key2]['N']\n",
    "    for dim in range(dataset_dimensionality):\n",
    "        COMPRESSION_SET_stats[key1]['sum'][dim] += COMPRESSION_SET_stats[key2]['sum'][dim]\n",
    "        COMPRESSION_SET_stats[key1]['sumsq'][dim] += COMPRESSION_SET_stats[key2]['sumsq'][dim]\n",
    "    COMPRESSION_SET_stats[key1]['stdev'] = np.sqrt(\n",
    "                                              (COMPRESSION_SET_stats[key1]['sumsq'] / COMPRESSION_SET_stats[key1]['N']) - \n",
    "                                              ((np.square(COMPRESSION_SET_stats[key1]['sum']) / COMPRESSION_SET_stats[key1]['N']**2))\n",
    "                                         )\n",
    "    COMPRESSION_SET_stats[key1]['centroid'] = COMPRESSION_SET_stats[key1]['sum'] / COMPRESSION_SET_stats[key1]['N']\n",
    "\n",
    "    # Remove the merged cluster\n",
    "    COMPRESSION_SET_stats.pop(key2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fantastic-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_CS_DS(keyCS, keyDS):\n",
    "    DISCARD_SET_stats[keyDS]['ids_in_cluster'].extend(COMPRESSION_SET_stats[keyCS]['ids_in_cluster'])\n",
    "    DISCARD_SET_stats[keyDS]['N'] += COMPRESSION_SET_stats[keyCS]['N']\n",
    "    for dim in range(dataset_dimensionality):\n",
    "        DISCARD_SET_stats[keyDS]['sum'][dim] += COMPRESSION_SET_stats[keyCS]['sum'][dim]\n",
    "        DISCARD_SET_stats[keyDS]['sumsq'][dim] += COMPRESSION_SET_stats[keyCS]['sumsq'][dim]\n",
    "    DISCARD_SET_stats[keyDS]['stdev'] = np.sqrt(\n",
    "                                              (DISCARD_SET_stats[keyDS]['sumsq'] / DISCARD_SET_stats[keyDS]['N']) - \n",
    "                                              ((np.square(DISCARD_SET_stats[keyDS]['sum']) / DISCARD_SET_stats[keyDS]['N']**2))\n",
    "                                         )\n",
    "    DISCARD_SET_stats[keyDS]['centroid'] = DISCARD_SET_stats[keyDS]['sum'] / DISCARD_SET_stats[keyDS]['N']\n",
    "\n",
    "    # Remove the merged cluster\n",
    "    COMPRESSION_SET_stats.pop(keyCS, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "yellow-culture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2 | DS Points: 128886 | CS Clusters: 10 | CS Points: 34 | RS Points: 6\n",
      "Round 3 | DS Points: 193326 | CS Clusters: 12 | CS Points: 59 | RS Points: 4\n",
      "Round 4 | DS Points: 257770 | CS Clusters: 10 | CS Points: 80 | RS Points: 2\n",
      "Round 5 | DS Points: 322216 | CS Clusters: 7 | CS Points: 94 | RS Points: 2\n"
     ]
    }
   ],
   "source": [
    "### Initialization is finished, run the regular iterations ###\n",
    "for curr_round in range(2,6):\n",
    "\n",
    "    # Load the samples for the iteration about the begin\n",
    "    if curr_round < 5:\n",
    "        iteration_samples = random.sample(unused_ids, sample_size)\n",
    "        for sample_id in iteration_samples:\n",
    "            unused_ids.remove(sample_id) \n",
    "    # The last iteration might have a slightly different number of samples\n",
    "    else:\n",
    "        iteration_samples = list(unused_ids.copy())\n",
    "        for sample_id in iteration_samples:\n",
    "            unused_ids.remove(sample_id) \n",
    "\n",
    "\n",
    "    ##################################\n",
    "    ### Assign Samples to DS/CS/RS ###\n",
    "    ##################################\n",
    "    \n",
    "    # Store the cluster which to send each new sample, in order to do a batch update after all samples are assigned\n",
    "    DS_clusters_ids = {key:[] for key in DISCARD_SET_stats.keys()}\n",
    "    CS_clusters_ids = {key:[] for key in COMPRESSION_SET_stats.keys()}\n",
    "\n",
    "    # Iterate over each sample among those drawn for this iterations\n",
    "    for sample_id in iteration_samples:\n",
    "\n",
    "        # Default to assuming points are in the RETAINED_SET\n",
    "        assigned_cluster = -1    \n",
    "\n",
    "        # Track the lowest distance between the sample and all clusters\n",
    "        lowest_dist = mahalanobis_threshold\n",
    "\n",
    "        # Find the DISCARD_SET cluster closest to the current sample      \n",
    "        for cluster_id, cluster_stats in DISCARD_SET_stats.items():\n",
    "\n",
    "            mahalanobis_distance = point_cluster_mahalanobis_distance(sample_id, cluster_stats)\n",
    "\n",
    "            # If the distance is under the mahalanobis_threshold and also the lowest distance yet found, update the point's cluster\n",
    "            if mahalanobis_distance < lowest_dist:\n",
    "                assigned_cluster = cluster_id\n",
    "                lowest_dist = mahalanobis_distance\n",
    "\n",
    "        # Update the statistics of the cluster to which the point is assigned \n",
    "        if assigned_cluster != -1:\n",
    "            DS_clusters_ids[assigned_cluster].append(sample_id)\n",
    "\n",
    "        # If the sample could not be assigned to any cluster in the DS, try assigning it to the CS\n",
    "        else:\n",
    "\n",
    "            # Find the COMPRESSION_SET cluster closest to the current sample\n",
    "            for cluster_id, cluster_stats in COMPRESSION_SET_stats.items():\n",
    "\n",
    "                mahalanobis_distance = point_cluster_mahalanobis_distance(sample_id, cluster_stats)\n",
    "\n",
    "                # If the distance is under the mahalanobis_threshold and also the lowest distance yet found, update the point's cluster\n",
    "                if mahalanobis_distance < lowest_dist:\n",
    "                    assigned_cluster = cluster_id\n",
    "                    lowest_dist = mahalanobis_distance\n",
    "\n",
    "            # Update the statistics of the cluster to which the point is assigned \n",
    "            if assigned_cluster != -1:\n",
    "                CS_clusters_ids[assigned_cluster].append(sample_id)\n",
    "\n",
    "            # If the algorithm also failed to assign the sample to a CS cluster, send it to the RS\n",
    "            else:\n",
    "                RETAINED_SET.append(sample_id)\n",
    "\n",
    "                \n",
    "    ###############################\n",
    "    ### Update DS & CS Clusters ###\n",
    "    ###############################    \n",
    "    \n",
    "    ### Update DS ###\n",
    "    for cluster_idx, new_datapoints in DS_clusters_ids.items():\n",
    "        \n",
    "        # If there are no new datapoints for the current cluster, skip\n",
    "        if len(new_datapoints) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Append the datapoints to the DS while extracting their features\n",
    "        features_matrix = []\n",
    "        for datapoint in new_datapoints:\n",
    "            DISCARD_SET_stats[cluster_idx]['ids_in_cluster'].append(datapoint)\n",
    "            features_matrix.append(dataset_dict[datapoint]['features'])\n",
    "        features_matrix = np.array(features_matrix)\n",
    "        \n",
    "        # Update N\n",
    "        DISCARD_SET_stats[cluster_idx]['N'] += len(new_datapoints)\n",
    "        \n",
    "        # Calculate SUM and SUMSQ for the new_datapoints\n",
    "        sum_new_datapoints = features_matrix.sum(axis=0)\n",
    "        sumsq_new_datapoints = np.sum(features_matrix**2, axis=0)\n",
    "        \n",
    "        # Update the DISCARD_SET_stats with the new SUM and SUMSQ\n",
    "        for dim in range(dataset_dimensionality):\n",
    "            DISCARD_SET_stats[cluster_idx]['sum'][dim] += sum_new_datapoints[dim]\n",
    "            DISCARD_SET_stats[cluster_idx]['sumsq'][dim] += sumsq_new_datapoints[dim]\n",
    "        \n",
    "        # Recalculate the Standard Deviation and Centroids\n",
    "        DISCARD_SET_stats[cluster_idx]['stdev'] = np.sqrt(\n",
    "                                                  (DISCARD_SET_stats[cluster_idx]['sumsq'] / DISCARD_SET_stats[cluster_idx]['N']) - \n",
    "                                                  (np.square(DISCARD_SET_stats[cluster_idx]['sum']) / DISCARD_SET_stats[cluster_idx]['N']**2)\n",
    "                                             )\n",
    "        DISCARD_SET_stats[cluster_idx]['centroid'] = DISCARD_SET_stats[cluster_idx]['sum'] / DISCARD_SET_stats[cluster_idx]['N']\n",
    "\n",
    "\n",
    "    ### Update CS ###\n",
    "    for cluster_idx, new_datapoints in CS_clusters_ids.items():\n",
    "        \n",
    "        # If there are no new datapoints for the current cluster, skip\n",
    "        if len(new_datapoints) == 0:\n",
    "            continue\n",
    "\n",
    "        # Append the datapoints to the CS while extracting their features\n",
    "        features_matrix = []\n",
    "        for datapoint in new_datapoints:\n",
    "            COMPRESSION_SET_stats[cluster_idx]['ids_in_cluster'].append(datapoint)\n",
    "            features_matrix.append(dataset_dict[datapoint]['features'])\n",
    "        features_matrix = np.array(features_matrix)\n",
    "\n",
    "        # Update N\n",
    "        COMPRESSION_SET_stats[cluster_idx]['N'] += len(new_datapoints)\n",
    "\n",
    "        # Calculate SUM and SUMSQ for the new_datapoints\n",
    "        sum_new_datapoints = features_matrix.sum(axis=0)\n",
    "        sumsq_new_datapoints = np.sum(features_matrix**2, axis=0)\n",
    "\n",
    "        # Update the COMPRESSION_SET_stats with the new SUM and SUMSQ\n",
    "        for dim in range(dataset_dimensionality):\n",
    "            COMPRESSION_SET_stats[cluster_idx]['sum'][dim] += sum_new_datapoints[dim]\n",
    "            COMPRESSION_SET_stats[cluster_idx]['sumsq'][dim] += sumsq_new_datapoints[dim]\n",
    "\n",
    "        # Recalculate the Standard Deviation and Centroids\n",
    "        COMPRESSION_SET_stats[cluster_idx]['stdev'] = np.sqrt(\n",
    "                                                  (COMPRESSION_SET_stats[cluster_idx]['sumsq'] / COMPRESSION_SET_stats[cluster_idx]['N']) - \n",
    "                                                  (np.square(COMPRESSION_SET_stats[cluster_idx]['sum']) / COMPRESSION_SET_stats[cluster_idx]['N']**2)\n",
    "                                             )\n",
    "        COMPRESSION_SET_stats[cluster_idx]['centroid'] = COMPRESSION_SET_stats[cluster_idx]['sum'] / COMPRESSION_SET_stats[cluster_idx]['N']\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    ### Create New CSs from RS Samples ###\n",
    "    ######################################\n",
    "\n",
    "    # Run KMeans on the RETAINED_SET and generate COMPRESSION_SET clusters\n",
    "    RS_sample_features = []\n",
    "    for sample_id in RETAINED_SET:\n",
    "        RS_sample_features.append(dataset_dict[sample_id]['features'])\n",
    "    X_train = np.array(RS_sample_features)\n",
    "    RS_clusters = {}\n",
    "    if X_train.shape[0] > 0:\n",
    "        kmeans = cluster.KMeans(n_clusters=min(7*n_cluster, int(1 + (X_train.shape[0]/2))))\n",
    "        predicted_clusters = kmeans.fit_predict(X_train)\n",
    "        for cluster_id, sampled_id in zip(predicted_clusters, RETAINED_SET):\n",
    "            # If there is no key for the current cluster id, create one\n",
    "            if RS_clusters.get(cluster_id) == None:\n",
    "                RS_clusters[cluster_id] = list()\n",
    "            # Then append the RS sample to the its newly found CS cluster\n",
    "            RS_clusters[cluster_id].append(sampled_id)\n",
    "\n",
    "\n",
    "    # Calculate the cluster statistics for the clusters generated from the initialization round\n",
    "    for key, value in RS_clusters.items():\n",
    "\n",
    "        # Only clusters with more than one sample in them go to the CS, those with only 1 sample remain RS \n",
    "        if len(value) > 1:\n",
    "\n",
    "            # Find the find the next cluster index to use for the COMPRESSION_SET_stats\n",
    "            try:\n",
    "                CS_stats_next_key = max(COMPRESSION_SET_stats.keys()) + 1\n",
    "            # If there are no keys from which to get the max value, then start at key 0\n",
    "            except:\n",
    "                CS_stats_next_key = 0\n",
    "\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key] = {'ids_in_cluster': []}\n",
    "            features_matrix = []\n",
    "            for datapoint in value:\n",
    "                COMPRESSION_SET_stats[CS_stats_next_key]['ids_in_cluster'].append(datapoint)\n",
    "                features_matrix.append(dataset_dict[datapoint]['features'])\n",
    "            features_matrix = np.array(features_matrix)\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key]['N'] = len(COMPRESSION_SET_stats[CS_stats_next_key]['ids_in_cluster'])\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key]['sum'] = features_matrix.sum(axis=0)\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key]['sumsq'] = np.sum(features_matrix**2, axis=0)\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key]['stdev'] = np.sqrt(\n",
    "                                                      (COMPRESSION_SET_stats[CS_stats_next_key]['sumsq'] / COMPRESSION_SET_stats[CS_stats_next_key]['N']) -\n",
    "                                                      (np.square(COMPRESSION_SET_stats[CS_stats_next_key]['sum']) / COMPRESSION_SET_stats[CS_stats_next_key]['N']**2) \n",
    "                                                 )\n",
    "            COMPRESSION_SET_stats[CS_stats_next_key]['centroid'] = COMPRESSION_SET_stats[CS_stats_next_key]['sum'] / COMPRESSION_SET_stats[CS_stats_next_key]['N']\n",
    "\n",
    "            # Clean the samples from the retained set which have been summarized\n",
    "            for datapoint in value:\n",
    "                RETAINED_SET.remove(datapoint)\n",
    "\n",
    "\n",
    "    #################################################\n",
    "    ### Merge CSs Below the Mahalanobis Threshold ###\n",
    "    #################################################\n",
    "\n",
    "    close_CSs = dict()\n",
    "    for key1, value1 in COMPRESSION_SET_stats.items():\n",
    "\n",
    "        # Default to assuming there is no other CS cluster close by\n",
    "        assigned_cluster = None\n",
    "\n",
    "        # Track the lowest distance between the sample and all clusters\n",
    "        lowest_dist = mahalanobis_threshold\n",
    "\n",
    "        # Compare each CS cluster to all other CS clusters\n",
    "        for key2, value2 in COMPRESSION_SET_stats.items():\n",
    "\n",
    "            # Do not compare the a cluster to itself\n",
    "            if key1 == key2:\n",
    "                continue\n",
    "\n",
    "            intercluster_dist = intercluster_mahalanobis_distance(value1, value2)\n",
    "\n",
    "            # If the intercluster distance is below the threshold, make the pair a candidate for merging\n",
    "            if intercluster_dist < lowest_dist:\n",
    "                assigned_cluster = key2\n",
    "                lowest_dist = intercluster_dist\n",
    "\n",
    "        # Once all pairwise comparisons were done for a given cluster (key1) store the results\n",
    "        close_CSs[key1] = assigned_cluster\n",
    "\n",
    "    # Once all closest CS clusters were found, merge them and update the COMPRESSION_SET_stats\n",
    "    for CS_cluster1, CS_cluster2 in close_CSs.items():\n",
    "        if CS_cluster1 in COMPRESSION_SET_stats and CS_cluster2 in COMPRESSION_SET_stats and CS_cluster1 != CS_cluster2:\n",
    "            merge_CS_CS(CS_cluster1, CS_cluster2)\n",
    "\n",
    "\n",
    "    ######################################################\n",
    "    ### At the Final Iteration Merge CSs to Nearby DSs ###\n",
    "    ######################################################\n",
    "\n",
    "    # Check if it is the last iteration\n",
    "    if curr_round == 5:\n",
    "\n",
    "        close_DSs = dict()\n",
    "        for CS_key, CS_value in COMPRESSION_SET_stats.items():\n",
    "\n",
    "            # Default to assuming there is no DS cluster close by\n",
    "            assigned_cluster = None\n",
    "\n",
    "            # Track the lowest distance between the sample and all clusters\n",
    "            lowest_dist = mahalanobis_threshold\n",
    "\n",
    "            for DS_key, DS_value in DISCARD_SET_stats.items():\n",
    "\n",
    "                intercluster_dist = intercluster_mahalanobis_distance(CS_value, DS_value)\n",
    "\n",
    "                # If the intercluster distance is below the threshold, make the pair a candidate for merging\n",
    "                if intercluster_dist < lowest_dist:\n",
    "                    assigned_cluster = DS_key\n",
    "                    lowest_dist = intercluster_dist\n",
    "\n",
    "            # Once all pairwise comparisons were done for a given cluster (CS_key) store the results\n",
    "            close_DSs[CS_key] = assigned_cluster\n",
    "\n",
    "        # Once all closest CS clusters were found, merge them and update the COMPRESSION_SET_stats\n",
    "        for CS_cluster, DS_cluster in close_DSs.items():\n",
    "            if CS_cluster in COMPRESSION_SET_stats and DS_cluster in DISCARD_SET_stats:\n",
    "                merge_CS_DS(CS_cluster, DS_cluster)\n",
    "\n",
    "\n",
    "    ###############################\n",
    "    ### Output Round Statistics ###\n",
    "    ###############################\n",
    "\n",
    "    # Objects to tally values to be outputted\n",
    "    num_DS_points = 0 \n",
    "    num_CS_clusters = 0\n",
    "    num_CS_points = 0\n",
    "    num_RS_points = 0\n",
    "\n",
    "    # Tally the values for outputting\n",
    "    for key, value in DISCARD_SET_stats.items():\n",
    "        num_DS_points += value['N']\n",
    "    for key, value in COMPRESSION_SET_stats.items():\n",
    "        num_CS_clusters += 1\n",
    "        num_CS_points += value['N']\n",
    "    num_RS_points = len(RETAINED_SET)\n",
    "\n",
    "    # Add the current round's results to the output file\n",
    "    f_out.write(\"\\n\" + \"Round \" + str(curr_round) + \": \" + str(num_DS_points) + \",\" + str(num_CS_clusters) + \",\" + str(num_CS_points) + \",\" + str(num_RS_points))\n",
    "    print(f\"Round {curr_round} | DS Points: {str(num_DS_points)} | CS Clusters: {str(num_CS_clusters)} | CS Points: {str(num_CS_points)} | RS Points: {str(num_RS_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-waterproof",
   "metadata": {},
   "source": [
    "## 5. Generate Predicted Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "challenging-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go over all sets (DS, CS, RS) and extract each datapoint's final cluster\n",
    "sample_id_to_cluster = dict()\n",
    "for key, value in DISCARD_SET_stats.items():\n",
    "    for datapoint in value['ids_in_cluster']:\n",
    "        sample_id_to_cluster[datapoint] = key\n",
    "for key, value in COMPRESSION_SET_stats.items():\n",
    "    for datapoint in value['ids_in_cluster']:\n",
    "        sample_id_to_cluster[datapoint] = -1\n",
    "for datapoint in RETAINED_SET:\n",
    "    sample_id_to_cluster[datapoint] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "third-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the clustering results\n",
    "f_out.write(\"\\n\" + \"\\n\" + \"The clustering results:\")\n",
    "for key, value in sorted(sample_id_to_cluster.items()):\n",
    "    f_out.write(\"\\n\" + str(key) + \",\" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-oriental",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "russian-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "positive-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the true clusters and their samples\n",
    "truth_clusters = {-1:[], 0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "for key, value in dataset_dict.items():\n",
    "    truth_clusters[value['true_cluster']].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bizarre-interview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 3, 2: 5, 3: 6, 4: 8, 5: 9, 6: 1, 7: 7, 8: 0, 9: 4}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the matching cluster IDs between the truth and the prediction \n",
    "# (because the points might be correctly clustered but the cluster number is most likely not the same)\n",
    "cluster_mapping = {}\n",
    "for true_cluster, true_members in truth_clusters.items():\n",
    "    \n",
    "    # The outliers won't have a matching cluster\n",
    "    if true_cluster == -1:\n",
    "        continue\n",
    "    \n",
    "    # Find the matching indexes by the size of matching elements in the clusters\n",
    "    largest_intersection = 0\n",
    "   \n",
    "    for pred_cluster, value in DISCARD_SET_stats.items():\n",
    "        pred_members = value['ids_in_cluster']\n",
    "        \n",
    "        # Check the number of points in both clusters (true and pred)\n",
    "        intersection_size = len(set(true_members) & set(pred_members))\n",
    "        \n",
    "        # If this is the largest match size thus far (for the true cluster), update the index matching\n",
    "        if intersection_size > largest_intersection:\n",
    "            cluster_mapping[true_cluster] = pred_cluster\n",
    "            largest_intersection = intersection_size\n",
    "            \n",
    "cluster_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "double-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store metrics for each cluster pair\n",
    "metrics_df = pd.DataFrame(columns = ['true_cluster', 'pred_cluster', 'true_size', 'pred_size', \n",
    "                                     'TP', 'FP', 'TN', 'FN', \n",
    "                                     'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Calculate TP, FP, TN, FN for each match\n",
    "total_samples = len(dataset_dict)\n",
    "for true_cluster, pred_cluster in cluster_mapping.items():\n",
    "    true_members = truth_clusters[true_cluster]\n",
    "    pred_members = DISCARD_SET_stats[pred_cluster]['ids_in_cluster']\n",
    "    \n",
    "    TP = len(set(true_members) & set(pred_members))\n",
    "    FP = len(set(pred_members) - set(true_members))\n",
    "    FN = len(set(true_members) - set(pred_members))\n",
    "    all_negative_preds = total_samples - len(pred_members)\n",
    "    TN = all_negative_preds - FN\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    scores = {'true_cluster':true_cluster, \n",
    "              'pred_cluster':pred_cluster,\n",
    "              'true_size': len(true_members),\n",
    "              'pred_size': len(pred_members),\n",
    "              'TP':TP, \n",
    "              'FP':FP, \n",
    "              'TN':TN, \n",
    "              'FN':FN, \n",
    "              'Accuracy':accuracy, \n",
    "              'Precision':precision, \n",
    "              'Recall':recall, \n",
    "              'F1 Score':F1}\n",
    "    \n",
    "    metrics_df = metrics_df.append([scores], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "published-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the items left in the COMPRESSION_SET and RETAINED_SET as outliers\n",
    "outliers = [sample for sample in RETAINED_SET]\n",
    "\n",
    "for value in COMPRESSION_SET_stats.values():\n",
    "    outliers = outliers + value['ids_in_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "shared-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then add to the metrics the scores related to outliers\n",
    "true_members = truth_clusters[-1]\n",
    "pred_members = outliers\n",
    "\n",
    "TP = len(set(true_members) & set(pred_members))\n",
    "FP = len(set(pred_members) - set(true_members))\n",
    "FN = len(set(true_members) - set(pred_members))\n",
    "all_negative_preds = total_samples - len(pred_members)\n",
    "TN = all_negative_preds - FN\n",
    "\n",
    "# Need to handle the possiblity of there being no outliers, in which case I'll consider a perfect score\n",
    "try:\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "except:\n",
    "    accuracy = 1.0\n",
    "\n",
    "try:\n",
    "    precision = TP / (TP + FP)\n",
    "except:\n",
    "    precision = 1.0\n",
    "\n",
    "try:\n",
    "    recall = TP / (TP + FN)\n",
    "except:\n",
    "    recall = 1.0\n",
    "    \n",
    "F1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "scores = {'true_cluster':-1, \n",
    "          'pred_cluster':-1,\n",
    "          'true_size': len(true_members),\n",
    "          'pred_size': len(pred_members),\n",
    "          'TP':TP, \n",
    "          'FP':FP, \n",
    "          'TN':TN, \n",
    "          'FN':FN, \n",
    "          'Accuracy':accuracy, \n",
    "          'Precision':precision, \n",
    "          'Recall':recall, \n",
    "          'F1 Score':F1}\n",
    "\n",
    "metrics_df = metrics_df.append([scores], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "prerequisite-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_cluster</th>\n",
       "      <th>pred_cluster</th>\n",
       "      <th>true_size</th>\n",
       "      <th>pred_size</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37859</td>\n",
       "      <td>37859</td>\n",
       "      <td>37859</td>\n",
       "      <td>0</td>\n",
       "      <td>284453</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23786</td>\n",
       "      <td>23786</td>\n",
       "      <td>23786</td>\n",
       "      <td>0</td>\n",
       "      <td>298526</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>37871</td>\n",
       "      <td>37871</td>\n",
       "      <td>37871</td>\n",
       "      <td>0</td>\n",
       "      <td>284441</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>30267</td>\n",
       "      <td>30270</td>\n",
       "      <td>30267</td>\n",
       "      <td>3</td>\n",
       "      <td>292042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>39655</td>\n",
       "      <td>39654</td>\n",
       "      <td>39654</td>\n",
       "      <td>0</td>\n",
       "      <td>282657</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>31210</td>\n",
       "      <td>31209</td>\n",
       "      <td>31209</td>\n",
       "      <td>0</td>\n",
       "      <td>291102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>32289</td>\n",
       "      <td>32289</td>\n",
       "      <td>32289</td>\n",
       "      <td>0</td>\n",
       "      <td>290023</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>35167</td>\n",
       "      <td>35169</td>\n",
       "      <td>35167</td>\n",
       "      <td>2</td>\n",
       "      <td>287143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22370</td>\n",
       "      <td>22370</td>\n",
       "      <td>22370</td>\n",
       "      <td>0</td>\n",
       "      <td>299942</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31738</td>\n",
       "      <td>31739</td>\n",
       "      <td>31738</td>\n",
       "      <td>1</td>\n",
       "      <td>290573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>322212</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_cluster pred_cluster true_size pred_size     TP FP      TN FN  \\\n",
       "0             0            2     37859     37859  37859  0  284453  0   \n",
       "1             1            3     23786     23786  23786  0  298526  0   \n",
       "2             2            5     37871     37871  37871  0  284441  0   \n",
       "3             3            6     30267     30270  30267  3  292042  0   \n",
       "4             4            8     39655     39654  39654  0  282657  1   \n",
       "5             5            9     31210     31209  31209  0  291102  1   \n",
       "6             6            1     32289     32289  32289  0  290023  0   \n",
       "7             7            7     35167     35169  35167  2  287143  0   \n",
       "8             8            0     22370     22370  22370  0  299942  0   \n",
       "9             9            4     31738     31739  31738  1  290573  0   \n",
       "10           -1           -1       100        96     96  0  322212  4   \n",
       "\n",
       "    Accuracy  Precision    Recall  F1 Score  \n",
       "0   1.000000   1.000000  1.000000  1.000000  \n",
       "1   1.000000   1.000000  1.000000  1.000000  \n",
       "2   1.000000   1.000000  1.000000  1.000000  \n",
       "3   0.999991   0.999901  1.000000  0.999950  \n",
       "4   0.999997   1.000000  0.999975  0.999987  \n",
       "5   0.999997   1.000000  0.999968  0.999984  \n",
       "6   1.000000   1.000000  1.000000  1.000000  \n",
       "7   0.999994   0.999943  1.000000  0.999972  \n",
       "8   1.000000   1.000000  1.000000  1.000000  \n",
       "9   0.999997   0.999968  1.000000  0.999984  \n",
       "10  0.999988   1.000000  0.960000  0.979592  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "minimal-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model performance (macro-averaged = each class/cluster has the same weight, regardless of samples)\n",
    "plot_metrics = {}\n",
    "plot_metrics['Precision'] = metrics_df['Precision'].mean()\n",
    "plot_metrics['Recall'] = metrics_df['Recall'].mean()\n",
    "plot_metrics['F1 Score'] = metrics_df['F1 Score'].mean()\n",
    "plot_metrics['Accuracy'] = metrics_df['Accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "designed-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.barplot(y=list(plot_metrics.keys()), x=list(plot_metrics.values()))\n",
    "plt.suptitle('Macro-Averaged Model Metrics')\n",
    "plt.gca().set_xticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_xticks()]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "optional-range",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 186 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f'Duration: {time.time() - start_time:.0f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-trademark",
   "metadata": {},
   "source": [
    "<h1 id=\"The-End\">The End<a class=\"anchor-link\" href=\"#The-End\">&#182;</a></h1><p>Matheus Schmitz<br>\n",
    "<a href=\"https://www.linkedin.com/in/matheusschmitz/\">LinkedIn</a><br>\n",
    "<a href=\"https://matheus-schmitz.github.io/\">Github Portfolio</a></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
